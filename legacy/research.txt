Title: VeinVision Pro – Research Protocol and Software Architecture

Overview
- Purpose: Build and evaluate a low-cost near-infrared (NIR) vein visualization device to aid venipuncture in patients with low vein visibility.
- Hardware: Raspberry Pi 4B, Raspberry Pi NoIR Camera v2 (IMX219), Arduino Uno, 850 nm IR LEDs, IR-pass filter, power and mounts.
- Software: Flask web app, OpenCV and scikit-image for image processing, PiCamera2 for capture, serial link to Arduino for LED control.

Software Architecture
1) Web Server (Flask) – app.py
   - REST endpoints for live MJPEG stream (/video_feed), capture (/capture), settings (/update_settings), LEDs (/toggle_leds), gallery, export, and health.
   - Thread-safe image processing using a processing lock to avoid race conditions.
   - Settings persisted in memory (exposure, gain, CLAHE, Frangi params, resolution, zoom, rotation).
   - Exports data bundles (images, metadata, patient info) and creates a report.

2) Camera Abstraction – camera.py
   - VeinCamera class wraps PiCamera2 with simulation fallback for development.
   - Stream resolutions normalized to 4:3 sensor modes for consistent FoV: 480p→640x480, 720p→1024x768, 1080p→1640x1232. High-res still captures at 1640x1232.
   - Methods: start/stop/update thread, read() live frame, capture_high_res() still, set_resolution(), adjust_settings(), save_image().

3) LED Control – led_controller.py
   - LEDController uses pyserial (or simulation) to set brightness, patterns, and on/off state via simple Arduino protocol: B<int>, P<int>, T<0|1>, Q (query).

4) Vein Detection – vein_detection.py
   - Preprocess: grayscale, CLAHE, median denoise.
   - Methods: adaptive thresholding, Frangi (tubular enhancement), Laplacian (edges). Tunables exposed via settings: CLAHE clip/tile, Frangi sigmas/beta/gamma.
   - Outputs 3-channel images suitable for JPEG encoding and overlay.

5) Web UI – templates/index.html, static/app.js, static/styles.css
   - Modern Bootstrap UI with live stream, controls for camera/LEDs/algorithms, method comparison, gallery, metadata modal, calibration wizard, and dark mode.
   - Gallery lists processed/original pairs with metadata; deletion and search supported.

Data Management
- Storage: static/images/ with filenames: vein_<YYYYMMDD>_<HHMMSS>_<usec>.jpg and vein_<...>_original.jpg.
- Metadata: static/images/metadata_<YYYYMMDD>_<HHMMSS>.json containing: timestamp, detection method, patient_info, camera_settings.
- Patient data: static/patient_data/*.json.
- Notes: static/notes/*.txt.
- Exports: static/exports/<patient|timerange>/* including images, metadata, patient_info.json, and report.html.

Security and Privacy
- No passwords stored in code; shutdown now requires sudoers configuration (see Operations). No outbound data by default. Patient data stored locally.
- Recommend network firewalling or authentication for clinical deployments.

Research Protocol
A) Study Design
- Objective: Compare visibility and reliability of NIR-enhanced vein visualization across algorithms and settings, and against baseline visual inspection.
- Participants: Adult volunteers with varying skin tones and BMI; include challenging cases (dehydration, edema).
- Sample size: Pilot N≈30–50 limbs for feasibility, iterate to larger N if needed.
- Ethics: Obtain IRB/ethics approval, consent forms, and anonymization plan.

B) Measurement Definitions
- Primary outcome: Vein visibility score (0–5 Likert) rated by blinded clinicians from captured images.
- Secondary outcomes: Time-to-first-stick, number of attempts, success rate, perceived confidence (0–5), SNR of vessel-to-background, vessel diameter in pixels.
- Environmental covariates: Ambient light (lux if available), skin temperature (optional), anatomical site, limb circumference.

C) Procedure per Subject
1. Record patient metadata: age range, skin tone (Fitzpatrick I–VI), anatomical site, hydration notes.
2. Position device 10–15 cm from skin, minimize visible light; enable IR LEDs.
3. Auto-optimize exposure/gain (optional) then fine-tune manually as needed.
4. Acquire one high-res still per algorithm: adaptive, frangi (set A), laplacian. Optionally vary parameters (Frangi sigmas, CLAHE clip) and LEDs (brightness/pattern).
5. Save images with patient_info in metadata; add notes on site and conditions.
6. If clinically performed: record success metrics (attempts, time), and operator feedback.

D) Standardized Settings
- Exposure: start 20,000 µs; adjust 10,000–80,000 µs as needed.
- Gain: 6–10 typical; avoid >12 if noise dominates.
- CLAHE: clip 3–7, tile 8–12.
- Frangi: sigmas 1–8 (step 1), beta 0.5–0.7, gamma 10–20.
- LED: brightness 150–255; pattern 1 for uniform illumination; consider pattern 2 for shadow cues.

E) Image Quality Metrics
- Compute SNR: mean intensity vessel region vs. background; use manual ROI or automated vein mask.
- Edge sharpness: Laplacian variance.
- Contrast improvement: histogram spread pre/post processing.
- Store metrics in extended metadata for analysis.

F) Analysis Plan
- Compare visibility scores across algorithms using repeated-measures ANOVA or Friedman test.
- Correlate SNR and clinician scores; analyze covariates (skin tone, BMI, site).
- Report effect sizes and confidence intervals; include failure/edge cases.

G) Validation and Benchmarks
- Phantom tests: printed tubular patterns under IR to quantify resolution and MTF.
- Repeatability: same site re-imaged 3× to measure variability.
- Stress tests: motion blur, varying ambient light, and LED brightness steps.

Operations
- Install: pip install -r requirements.txt; Arduino sketch upload as documented.
- Run: python app.py --port 8000 [--dev] [--debug]
- Shutdown: Configure passwordless shutdown for www-data or user:
  1) sudo visudo
  2) Add: <user> ALL=(ALL) NOPASSWD: /sbin/shutdown
  The app now calls "sudo shutdown -h now" without embedding passwords.

Quality Gates
- Lint/Type: Python 3.11 compatible; OpenCV, scikit-image validated by system_check.py.
- Runtime smoke tests: app.py launches, video_feed emits frames (simulated on non-RPi), capture saves images and metadata, gallery loads.

Future Work
- Add authentication and role-based access.
- Add quantitative metric computation and export CSV.
- Support thermal camera fusion (if available) as a method.
- Implement on-device analytics and offline sync for research datasets.
- Add unit/integration tests and CI on Raspberry Pi runner.

Citations
- Frangi AF et al. Multiscale vessel enhancement filtering. MICCAI 1998.
- Zuiderveld K. Contrast Limited Adaptive Histogram Equalization. Graphics Gems IV, 1994.
